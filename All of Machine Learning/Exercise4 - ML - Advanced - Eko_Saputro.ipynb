{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Python Machine Learning with PACMANN AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Sentiment Analysis : Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataset Information\n",
    "\n",
    "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\"). From this data we can analyze how travelers in February 2015 expressed their feelings on Twitter.\n",
    " \n",
    "Source : https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    " \n",
    "### Content\n",
    "Original data contains 15 columns : tweet_id, airline_sentiment, airline_sentiment_confidence, negativereason, negativereason_confidence, airline, airline_sentiment_gold, name, negativereason_gold, retweet_count, text, tweet_coord, tweet_created, tweet_location, user_timezone\n",
    "\n",
    "In this exercise we only do preprocessing for time, coordinate, and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Data to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libary pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data training_text.csv\n",
    "\n",
    "data = pd.read_csv('../datasets/training_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       time coordinate  \\\n",
       "0           0  2015-02-24 11:35:52 -0800        NaN   \n",
       "1           1  2015-02-24 11:15:59 -0800        NaN   \n",
       "2           2  2015-02-24 11:15:48 -0800        NaN   \n",
       "3           3  2015-02-24 11:15:36 -0800        NaN   \n",
       "4           4  2015-02-24 11:14:45 -0800        NaN   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "time              0\n",
       "coordinate    13621\n",
       "text              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek apakah ada data yang kosong\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Time\n",
    "Informasi pada kolom `time` sebaiknya diurai menjadi kolom-kolom tertentu agar dapat diproses dengan lebih baik oleh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek tipe data dari kolom time\n",
    "\n",
    "type(data['time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ambil data kolom 'time'\n",
    "# assign ke variabel data_time\n",
    "\n",
    "data_time = data['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015-02-24 11:35:52 -0800\n",
       "1    2015-02-24 11:15:59 -0800\n",
       "2    2015-02-24 11:15:48 -0800\n",
       "3    2015-02-24 11:15:36 -0800\n",
       "4    2015-02-24 11:14:45 -0800\n",
       "Name: time, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data_time\n",
    "\n",
    "data_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pisahkan isi data berdasarkan spasi : ' '\n",
    "\n",
    "data_time = data_time.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ubah ke dalam bentuk list\n",
    "\n",
    "data_time = data_time.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# buat ke dalam DataFrame\n",
    "# pastikan indeksnya tidak berubah\n",
    "\n",
    "data_time_df = pd.DataFrame(data_time, index = data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:35:52</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:59</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:48</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:36</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:14:45</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1      2\n",
       "0  2015-02-24  11:35:52  -0800\n",
       "1  2015-02-24  11:15:59  -0800\n",
       "2  2015-02-24  11:15:48  -0800\n",
       "3  2015-02-24  11:15:36  -0800\n",
       "4  2015-02-24  11:14:45  -0800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "data_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ganti nama kolom agar sesuai\n",
    "\n",
    "data_time_df.columns = ['date','time','GMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>GMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:35:52</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:59</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:48</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:15:36</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>11:14:45</td>\n",
       "      <td>-0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time    GMT\n",
       "0  2015-02-24  11:35:52  -0800\n",
       "1  2015-02-24  11:15:59  -0800\n",
       "2  2015-02-24  11:15:48  -0800\n",
       "3  2015-02-24  11:15:36  -0800\n",
       "4  2015-02-24  11:14:45  -0800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "data_time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise!\n",
    "* Uraikan kolom ['date'] menjadi kolom ['year','month','day']\n",
    "* Uraikan kolom ['time] menjadi kolom ['hour','minute','second']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_data = data_time_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015-02-24\n",
       "1    2015-02-24\n",
       "2    2015-02-24\n",
       "3    2015-02-24\n",
       "4    2015-02-24\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_data = date_data.str.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_data = date_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_data_df = pd.DataFrame(date_data, index = data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2\n",
       "0  2015  02  24\n",
       "1  2015  02  24\n",
       "2  2015  02  24\n",
       "3  2015  02  24\n",
       "4  2015  02  24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_data_df.columns = ['year', 'month', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month day\n",
       "0  2015    02  24\n",
       "1  2015    02  24\n",
       "2  2015    02  24\n",
       "3  2015    02  24\n",
       "4  2015    02  24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_data = data_time_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11:35:52\n",
       "1    11:15:59\n",
       "2    11:15:48\n",
       "3    11:15:36\n",
       "4    11:14:45\n",
       "Name: time, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_data = time_data.str.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_data = time_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_data_df = pd.DataFrame(time_data, index = data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  11  35  52\n",
       "1  11  15  59\n",
       "2  11  15  48\n",
       "3  11  15  36\n",
       "4  11  14  45"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_data_df.columns = ['hour', 'minute', 'second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hour minute second\n",
       "0   11     35     52\n",
       "1   11     15     59\n",
       "2   11     15     48\n",
       "3   11     15     36\n",
       "4   11     14     45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Coordinate \n",
    "Informasi pada kolom `coordinate` sebaiknya diurai menjadi kolom-kolom tertentu agar dapat diproses dengan lebih baik oleh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek tipe data dari kolom coordinate\n",
    "\n",
    "type(data['coordinate'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "Name: coordinate, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ambil data coordinate\n",
    "\n",
    "data_coordinate = data['coordinate']\n",
    "data_coordinate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]                      0.160942\n",
       "[40.64656067, -73.78334045]     0.005888\n",
       "[32.91792297, -97.00367737]     0.002944\n",
       "[40.64646912, -73.79133606]     0.002944\n",
       "[39.1766101, -76.6700606]       0.001963\n",
       "[40.69017276, -73.91646118]     0.001963\n",
       "[32.82813261, -97.25115941]     0.001963\n",
       "[39.83426941, -104.69960636]    0.001963\n",
       "[34.0213466, -118.45229268]     0.001963\n",
       "[37.99311597, -84.52114659]     0.001963\n",
       "[40.69002464, -73.91638072]     0.001963\n",
       "[18.22245647, -63.00369733]     0.001963\n",
       "[40.68996177, -73.91640136]     0.001963\n",
       "[33.75539049, -116.36196163]    0.001963\n",
       "[35.22643463, -80.93879965]     0.001963\n",
       "[33.75348859, -116.36209633]    0.001963\n",
       "[40.68994668, -73.91637642]     0.001963\n",
       "[37.62006843, -122.38822083]    0.001963\n",
       "[37.78618135, -122.45742542]    0.001963\n",
       "[29.98442078, -90.25340271]     0.000981\n",
       "[39.86311565, -104.67610845]    0.000981\n",
       "[41.97888728, -87.90617197]     0.000981\n",
       "[41.97862209, -87.91469774]     0.000981\n",
       "[34.02763089, -118.49627894]    0.000981\n",
       "[42.361016, -71.02000488]       0.000981\n",
       "[39.8893997, -75.219676]        0.000981\n",
       "[29.7420124, -95.5606921]       0.000981\n",
       "[29.98378319, -95.33473143]     0.000981\n",
       "[25.79939784, -80.27038889]     0.000981\n",
       "[37.78915629, -122.4148408]     0.000981\n",
       "                                  ...   \n",
       "[40.69522398, -74.1760931]      0.000981\n",
       "[33.94729537, -118.40196951]    0.000981\n",
       "[-38.0269936, 145.2110041]      0.000981\n",
       "[39.1766716, -76.6694354]       0.000981\n",
       "[39.87455718, -75.24082121]     0.000981\n",
       "[37.93609081, -107.81826687]    0.000981\n",
       "[33.7008468, -118.0192094]      0.000981\n",
       "[41.24222981, -77.02647239]     0.000981\n",
       "[4.69840554, -74.14134323]      0.000981\n",
       "[41.06938783, -73.73394372]     0.000981\n",
       "[36.08576903, -115.14953095]    0.000981\n",
       "[39.98272482, -86.22502919]     0.000981\n",
       "[35.8271843, -87.43714049]      0.000981\n",
       "[41.19758614, -73.76914167]     0.000981\n",
       "[35.2238122, -80.9435393]       0.000981\n",
       "[43.19825137, -70.87335749]     0.000981\n",
       "[39.87414824, -75.25238981]     0.000981\n",
       "[40.89343356, -74.29961359]     0.000981\n",
       "[36.08546367, -115.31814055]    0.000981\n",
       "[40.71716644, -73.96426215]     0.000981\n",
       "[25.7789509, -80.1353866]       0.000981\n",
       "[30.44405028, -84.23614305]     0.000981\n",
       "[40.64527481, -73.77615604]     0.000981\n",
       "[32.90431463, -97.03489789]     0.000981\n",
       "[38.88839871, -94.62041633]     0.000981\n",
       "[37.62068265, -122.38816957]    0.000981\n",
       "[45.67912434, -111.04847959]    0.000981\n",
       "[35.46005368, -80.68267946]     0.000981\n",
       "[34.10971017, -118.32188864]    0.000981\n",
       "[37.6208766, -122.3867929]      0.000981\n",
       "Name: coordinate, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lihat bentuk data dengan value_counts\n",
    "\n",
    "data_coordinate.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# isi data kosong dengan nilai 0.0 dan sesuaikan formatnya\n",
    "\n",
    "data_coordinate = data_coordinate.fillna(value = \"[0.0, 0.0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.0]\n",
       "1    [0.0, 0.0]\n",
       "2    [0.0, 0.0]\n",
       "3    [0.0, 0.0]\n",
       "4    [0.0, 0.0]\n",
       "Name: coordinate, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "data_coordinate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ambil bagian data yang diperlukan\n",
    "\n",
    "data_coordinate = data_coordinate.str[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0, 0.0\n",
       "1    0.0, 0.0\n",
       "2    0.0, 0.0\n",
       "3    0.0, 0.0\n",
       "4    0.0, 0.0\n",
       "Name: coordinate, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "data_coordinate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise!\n",
    "* Uraikan kolom ['coordinate'] menjadi kolom [\"latitude\", \"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coord_data = data_coordinate.str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coord_data = coord_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord_data_df = pd.DataFrame(coord_data, index = data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  0.0   0.0\n",
       "1  0.0   0.0\n",
       "2  0.0   0.0\n",
       "3  0.0   0.0\n",
       "4  0.0   0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord_data_df.columns = ['latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  latitude longitude\n",
       "0      0.0       0.0\n",
       "1      0.0       0.0\n",
       "2      0.0       0.0\n",
       "3      0.0       0.0\n",
       "4      0.0       0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# cek tipe data dari masing-masin kolom [\"latitude\", \"longitude\"]\n",
    "\n",
    "print(type(coord_data_df['latitude'][0]))\n",
    "print(type(coord_data_df['longitude'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kembalikan data kolom [\"latitude\", \"longitude\"] ke dalam format numerik, gunakan : <br>\n",
    "data[column_name] = pd.to_numeric(data[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord_data_df['latitude'] = pd.to_numeric(coord_data_df['latitude'])\n",
    "coord_data_df['longitude'] = pd.to_numeric(coord_data_df['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(coord_data_df['latitude'][0]))\n",
    "print(type(coord_data_df['longitude'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise!\n",
    "### Buat function untuk memisahkan data pada sebuah kolom\n",
    "\n",
    "Function dinamakan dengan `columnSplit` dan menerima 3 argument yaitu:\n",
    "\n",
    " 1. `data`: kolom data yang hendak dipisahkan\n",
    " 2. `splitter`    : batas pemisah pada data\n",
    " 3. `columns_name` : nama kolom baru\n",
    " \n",
    "Lalu assign function tersebut pada suatu variabel yang dengan nama `data_ .... `\n",
    "\n",
    "Kemudian lakukan kembali pemisahan dengan menggunakan function columnSplit pada : \n",
    "* kolom data['time'] menjadi kolom ['date', 'time','GMT']\n",
    "* kolom ['date'] menjadi kolom ['year','month','day']\n",
    "* kolom ['time] menjadi kolom ['hour','minute','second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define columnSplit function\n",
    "\n",
    "def columnSplit(data, splitter, columns_name):\n",
    "    data = pd.DataFrame(data.str.split(splitter).tolist(),\n",
    "                        columns = columns_name,\n",
    "                        index = data.index)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kolom data['time'] menjadi kolom ['date', 'time','GMT']\n",
    "\n",
    "data_time_full = columnSplit(data['time'], ' ', ['date', 'time', 'GMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kolom ['date'] menjadi kolom ['year','month','day']\n",
    "\n",
    "data_date = columnSplit(data_time_full['date'], '-', ['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kolom ['time] menjadi kolom ['hour','minute','second']\n",
    "\n",
    "data_hour = columnSplit(data_time_full['time'], ':', ['hour', 'minute', 'second'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ambil data dari kolom data[\"text\"] \n",
    "\n",
    "text = data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  i. Regular Expression\n",
    "\n",
    "A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing).\n",
    "<br>\n",
    "Further reference : https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf (p1-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import library re\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil data baris tertentu, misal 7\n",
    "\n",
    "raw_text = text[7]\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pastikan formatnya menjadi string\n",
    "\n",
    "raw_text = str(raw_text)\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cek dokumentasi dari re.sub\n",
    "?re.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.sub(pattern, repl, string, count=0, flags=0) : <br>\n",
    "Return the string obtained by replacing the leftmost\n",
    "non-overlapping occurrences of the pattern in string by the\n",
    "replacement repl.  repl can be either a string or a callable;\n",
    "if a string, backslash escapes in it are processed.  If it is\n",
    "a callable, it's passed the match object and must return\n",
    "a replacement string to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' VirginAmerica Really missed a prime opportunity for Men Without Hats parody there https t co mWpG7grEZP'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hapus simbol pada teks, ganti menjadi spasi\n",
    "\n",
    "# '[^A-Za-z0-9]+'  :\n",
    "#    [] menujukkan himpunan yang diinginkan\n",
    "#    - menunjukkan range\n",
    "#    ^ menunjukkan negasi\n",
    "#    + menunjukkan teks dengan karakter sejenis\n",
    "#      misal : baa+ dapat merujuk pada baa, baaa, baaaa, baaaaa\n",
    "\n",
    "raw_text = re.sub('[^A-Za-z0-9]+', ' ', raw_text)\n",
    "\n",
    "#  argumen diatas memiliki arti untuk karakter selain A-Z,a-z,dan 0-9 akan diganti menjadi ' ' (spasi)\n",
    "\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VirginAmerica Really missed a prime opportunity for Men Without Hats parody there https t co mWpG7grEZP'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hapus spasi berlebih\n",
    "\n",
    "raw_text = re.sub(' +',' ',raw_text.strip())\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica really missed a prime opportunity for men without hats parody there https t co mwpg7grezp'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ubah menjadi huruf kecil\n",
    "\n",
    "raw_text = raw_text.lower()\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Stemming and Lemmatization\n",
    "\n",
    "For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set.\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "> am, are, is $\\Rightarrow$ be <br>\n",
    "> car, cars, car's, cars' $\\Rightarrow$ car<br>\n",
    "> cats, catty  $\\Rightarrow$ cat <br>\n",
    "> stemming, stemmer, stemmed  $\\Rightarrow$ stem <br>\n",
    "> fisher, fishing, fished  $\\Rightarrow$ fish\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    ">the boy's cars are different colors $\\Rightarrow$ the boy car be differ color\n",
    "\n",
    "However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma <br><br>\n",
    "\n",
    "Further reference : https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import library untuk stem\n",
    "\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reference on SnowballStemmer : http://snowball.tartarus.org/texts/introduction.html <br>\n",
    "Further reference on WordNetLemmatizer : https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>======================================================================</font><br>\n",
    "Sebelum melakukan \"Stemming and Lemmatization\", ekstrak isi nltk_data.rar ke Drive C:<br>\n",
    "Pastikan directory C:\\nltk_data\\corpora berisi folder wordnet dan file wordnet.zip\n",
    "<font color='red'>======================================================================</font><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica really missed a prime opportunity for men without hats parody there https t co mwpg7grezp'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil data raw_text, assign ke stem_text\n",
    "\n",
    "stem_text = str(raw_text)\n",
    "stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'really',\n",
       " 'missed',\n",
       " 'a',\n",
       " 'prime',\n",
       " 'opportunity',\n",
       " 'for',\n",
       " 'men',\n",
       " 'without',\n",
       " 'hats',\n",
       " 'parody',\n",
       " 'there',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'mwpg7grezp']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pisahkan kalimat ke dalam kata berdasarkan spasi\n",
    "\n",
    "stem_text = stem_text.split(\" \")\n",
    "stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'realli',\n",
       " 'miss',\n",
       " 'a',\n",
       " 'prime',\n",
       " 'opportun',\n",
       " 'for',\n",
       " 'men',\n",
       " 'without',\n",
       " 'hat',\n",
       " 'parodi',\n",
       " 'there',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'mwpg7grezp']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lakukan stem dengan stemmer untuk tiap kata dalam kalimat\n",
    "\n",
    "stem_text = [stemmer.stem(word) for word in stem_text]\n",
    "stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica realli miss a prime opportun for men without hat parodi there https t co mwpg7grezp'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gabung kembali kata-kata menjadi kalimat\n",
    "\n",
    "stem_text = \" \".join(stem_text)\n",
    "stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'realli',\n",
       " 'miss',\n",
       " 'a',\n",
       " 'prime',\n",
       " 'opportun',\n",
       " 'for',\n",
       " 'men',\n",
       " 'without',\n",
       " 'hat',\n",
       " 'parodi',\n",
       " 'there',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'mwpg7grezp']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil stem_text dan assign ke lemmatize_text\n",
    "# pisahkan tiap kata dalam kalimat berdasarkan spasi\n",
    "\n",
    "lemmatize_text = stem_text.split(\" \")\n",
    "lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'realli',\n",
       " 'miss',\n",
       " 'a',\n",
       " 'prime',\n",
       " 'opportun',\n",
       " 'for',\n",
       " 'men',\n",
       " 'without',\n",
       " 'hat',\n",
       " 'parodi',\n",
       " 'there',\n",
       " 'http',\n",
       " 't',\n",
       " 'co',\n",
       " 'mwpg7grezp']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize tiap kata dalam kalimat\n",
    "\n",
    "lemmatize_text = [lemmatizer.lemmatize(word) for word in lemmatize_text]\n",
    "lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica realli miss a prime opportun for men without hat parodi there http t co mwpg7grezp'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gabung tiap kata-kata menjadi kalimat\n",
    "\n",
    "lemmatize_text = \" \".join(lemmatize_text)\n",
    "lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginamerica really missed a prime opportunity for men without hats parody there https t co mwpg7grezp\n",
      "virginamerica realli miss a prime opportun for men without hat parodi there https t co mwpg7grezp\n",
      "virginamerica realli miss a prime opportun for men without hat parodi there http t co mwpg7grezp\n"
     ]
    }
   ],
   "source": [
    "# tampilkan raw_text, stem_text, dan lemmatize_text\n",
    "# amati perbedaannya\n",
    "\n",
    "print(raw_text)\n",
    "print(stem_text)\n",
    "print(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise!\n",
    "* Lakukan preprocessing text seperti di atas pada baris data text yang lain, misal text[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = text[9]\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = str(text9)\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' VirginAmerica it was amazing and arrived an hour early You re too good to me '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = re.sub('[^A-Za-z0-9]+', ' ', text9)\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VirginAmerica it was amazing and arrived an hour early You re too good to me'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = re.sub(' +', ' ', text9.strip())\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica it was amazing and arrived an hour early you re too good to me'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = text9.lower()\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'it',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'arrived',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'early',\n",
       " 'you',\n",
       " 're',\n",
       " 'too',\n",
       " 'good',\n",
       " 'to',\n",
       " 'me']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text9 = text9.split(' ')\n",
    "stem_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'it',\n",
       " 'was',\n",
       " 'amaz',\n",
       " 'and',\n",
       " 'arriv',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'earli',\n",
       " 'you',\n",
       " 're',\n",
       " 'too',\n",
       " 'good',\n",
       " 'to',\n",
       " 'me']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text9 = [stemmer.stem(word) for word in stem_text9]\n",
    "stem_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica it was amaz and arriv an hour earli you re too good to me'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text9 = ' '.join(stem_text9)\n",
    "stem_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'it',\n",
       " 'was',\n",
       " 'amaz',\n",
       " 'and',\n",
       " 'arriv',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'earli',\n",
       " 'you',\n",
       " 're',\n",
       " 'too',\n",
       " 'good',\n",
       " 'to',\n",
       " 'me']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text9 = stem_text9.split(' ')\n",
    "lemmatize_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'amaz',\n",
       " 'and',\n",
       " 'arriv',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'earli',\n",
       " 'you',\n",
       " 're',\n",
       " 'too',\n",
       " 'good',\n",
       " 'to',\n",
       " 'me']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text9 = [lemmatizer.lemmatize(word) for word in lemmatize_text9]\n",
    "lemmatize_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica it wa amaz and arriv an hour earli you re too good to me'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text9 = ' '.join(lemmatize_text9)\n",
    "lemmatize_text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginamerica it was amazing and arrived an hour early you re too good to me\n",
      "virginamerica it was amaz and arriv an hour earli you re too good to me\n",
      "virginamerica it wa amaz and arriv an hour earli you re too good to me\n"
     ]
    }
   ],
   "source": [
    "print(text9)\n",
    "print(stem_text9)\n",
    "print(lemmatize_text9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### re, Stem, Lemmatize pada seluruh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_text = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in text.index:\n",
    "    string = str(text[i])\n",
    "    string = re.sub('[^A-Za-z0-9]+', ' ', string)    \n",
    "    string = re.sub(' +',' ',string.strip())\n",
    "    clear_text[i] = string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus you ve added commercials to...\n",
       "2    virginamerica i didn t today must mean i need ...\n",
       "3    virginamerica it s really aggressive to blast ...\n",
       "4    virginamerica and it s a really big bad thing ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stem_text = pd.Series([])\n",
    "lemmatize_text = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in clear_text.index:\n",
    "    string = clear_text[i]\n",
    "    string = str(string)\n",
    "    string = string.split(\" \")\n",
    "    string = [stemmer.stem(word) for word in string]\n",
    "    string = \" \".join(string)\n",
    "    stem_text[i] = str(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus you ve ad commerci to the e...\n",
       "2    virginamerica i didn t today must mean i need ...\n",
       "3    virginamerica it s realli aggress to blast obn...\n",
       "4    virginamerica and it s a realli big bad thing ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in stem_text.index:\n",
    "    string = stem_text[i]\n",
    "    string = str(string)\n",
    "    string = string.split(\" \")\n",
    "    string = [lemmatizer.lemmatize(word) for word in string]\n",
    "    string = \" \".join(string)\n",
    "    lemmatize_text[i] = str(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus you ve ad commerci to the e...\n",
       "2    virginamerica i didn t today must mean i need ...\n",
       "3    virginamerica it s realli aggress to blast obn...\n",
       "4    virginamerica and it s a realli big bad thing ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text = lemmatize_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. TF-IDF\n",
    "\n",
    "TF: Term Frequency <br>\n",
    "Measures how frequently a term occurs in a document<br><br>\n",
    "IDF: Inverse Document Frequency<br>\n",
    "Measures how important a term is<br><br>\n",
    "Further reference : Chapter 15.2 from Christopher D. Manning, Hinrich Schütze-Foundations of Statistical Natural Language Processing-The MIT Press (1999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=500, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keterangan argument input untuk TfidfVectorizer : <br>\n",
    "min_df : float in range [0.0, 1.0] or int, default=1\n",
    "    > When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly lower than the given threshold. This value is also\n",
    "    called cut-off in the literature.\n",
    "    If float, the parameter represents a proportion of documents, integer\n",
    "    absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    " \n",
    "stop_words : string {'english'}, list, or None (default)\n",
    "    > If a string, it is passed to _check_stop_list and the appropriate stop\n",
    "    list is returned. 'english' is currently the only supported string\n",
    "    value.\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=500,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit vectorizer\n",
    "\n",
    "vectorizer.fit(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data clean_text\n",
    "\n",
    "tf_idf = vectorizer.transform(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# buat hasil TfidfVectorizer ke dalam DataFrame\n",
    "\n",
    "feature_word = pd.DataFrame(tf_idf.toarray(), columns=vectorizer.get_feature_names(), \n",
    "                                index = text.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airlin</th>\n",
       "      <th>americanair</th>\n",
       "      <th>amp</th>\n",
       "      <th>bag</th>\n",
       "      <th>cancel</th>\n",
       "      <th>custom</th>\n",
       "      <th>day</th>\n",
       "      <th>delay</th>\n",
       "      <th>fli</th>\n",
       "      <th>flight</th>\n",
       "      <th>...</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>tri</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>virginamerica</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>whi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airlin  americanair       amp  bag  cancel  custom  day  delay  fli  \\\n",
       "0     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "1     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "2     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "3     0.0          0.0  0.692405  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "4     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "\n",
       "   flight ...   southwestair  thank  time  tri  unit  usairway  virginamerica  \\\n",
       "0     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "1     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "2     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       0.727886   \n",
       "3     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       0.721509   \n",
       "4     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "\n",
       "    wa  wait  whi  \n",
       "0  0.0   0.0  0.0  \n",
       "1  0.0   0.0  0.0  \n",
       "2  0.0   0.0  0.0  \n",
       "3  0.0   0.0  0.0  \n",
       "4  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek head dari data\n",
    "\n",
    "feature_word.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise!\n",
    "### Buat function untuk memisahkan data pada sebuah kolom\n",
    "\n",
    "Function dinamakan dengan `tfidfFeature` dan menerima 2 argument yaitu:\n",
    "\n",
    " 1. `text`: kolom data yang hendak dipisahkan\n",
    " 2. `vectorizer`    : batas pemisah pada data\n",
    "\n",
    "Function mengembalikan `feature_word` dan `vectorizer` yang telah difit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=500, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function\n",
    "\n",
    "def tfidfFeature(text, vectorizer):\n",
    "    vectorizer.fit(text)\n",
    "    \n",
    "    tf_idf = vectorizer.transform(text)\n",
    "    feature_word = pd.DataFrame(tf_idf.toarray(),\n",
    "                               columns=vectorizer.get_feature_names(),\n",
    "                               index=text.index)\n",
    "    \n",
    "    return feature_word, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_word, tfidf = tfidfFeature(clean_text, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airlin</th>\n",
       "      <th>americanair</th>\n",
       "      <th>amp</th>\n",
       "      <th>bag</th>\n",
       "      <th>cancel</th>\n",
       "      <th>custom</th>\n",
       "      <th>day</th>\n",
       "      <th>delay</th>\n",
       "      <th>fli</th>\n",
       "      <th>flight</th>\n",
       "      <th>...</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>tri</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>virginamerica</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>whi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airlin  americanair       amp  bag  cancel  custom  day  delay  fli  \\\n",
       "0     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "1     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "2     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "3     0.0          0.0  0.692405  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "4     0.0          0.0  0.000000  0.0     0.0     0.0  0.0    0.0  0.0   \n",
       "\n",
       "   flight ...   southwestair  thank  time  tri  unit  usairway  virginamerica  \\\n",
       "0     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "1     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "2     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       0.727886   \n",
       "3     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       0.721509   \n",
       "4     0.0 ...            0.0    0.0   0.0  0.0   0.0       0.0       1.000000   \n",
       "\n",
       "    wa  wait  whi  \n",
       "0  0.0   0.0  0.0  \n",
       "1  0.0   0.0  0.0  \n",
       "2  0.0   0.0  0.0  \n",
       "3  0.0   0.0  0.0  \n",
       "4  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
